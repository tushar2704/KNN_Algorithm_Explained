{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tusharaggarwal27/knn-algorithm-explained?scriptVersionId=124031311\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:2px;\n           background-color:#F5DEB3;\n           font-size:250%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n<p style=\"padding: 10px;\n          text-align: center;\n          font-size:150%;\n          color:blue;\">\n           ðŸŽ¯ ðŸŽ¯KNN AlgorithmðŸŽ¯ðŸŽ¯  \n</p>\n<style>\n        h1{text-align: center;}\n </style>  \n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:cursive; font-size:25px; color:'darkcyan';\">I brewed this notebook from scratch, If this notebook helped, please consider upvoting and cite me if sharing on other platforms.</p>\n\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;font-size:23px;border-radius:20px\">\n    <a href=\"https://www.linkedin.com/in/tusharaggarwalinseec/\" target=\"_blank\">Lets connect on LinkedIn!</a>\n    \n   </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;border-radius:20px\">\n<a href=\"https://github.com/tushar2704\" target=\"_blank\">Follow me on Github too!</a> </p>\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;border-radius:20px\">\n    <a href=\"https://medium.com/@tushar_aggarwal\" target=\"_blank\">Also checkout my Medium posts!</a>\n    \n   </p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:10px;\n           background-color: #ffaa00;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: left;\n          color:black;\">\nIn this notebook, I used KNN i.e.(KNeighborsClassifier), to classify if target class is 1 or o with \"classified-data\"(cleaned already).\n\n Note:I completely brewed this notebbok from cratch, if you learn anything from it please consider upvoting and cite me if sharing on other platforms.\n\n</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:skyblue;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\n This dataset contains current estimates (live population clock), historical data, and projected figures of world countries and dependent territories. Data based on the latest United Nations Population Division estimates.\n\n</p>\n   ","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:#e71837;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPlease note, I have already cleaned and placed the data as \"classified-data\" so that reader of this notebook can focus on builing the KKN and not distracted by the data cleaing here. In real world data will always require some sort of wrangling, to see checkout my other notebooks!\n</p>\n","metadata":{"execution":{"iopub.status.busy":"2022-12-10T13:39:56.401073Z","iopub.execute_input":"2022-12-10T13:39:56.401596Z","iopub.status.idle":"2022-12-10T13:39:56.438444Z","shell.execute_reply.started":"2022-12-10T13:39:56.401486Z","shell.execute_reply":"2022-12-10T13:39:56.437143Z"}}},{"cell_type":"markdown","source":"\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#fc9303;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nK Nearest Neighbor algorithm falls under the Supervised Learning category and is used for classification (most commonly) and regression. It is a versatile algorithm also used for imputing missing values and resampling datasets. As the name (K Nearest Neighbor) suggests it considers K Nearest Neighbors (Data points) to predict the class or continuous value for the new Datapoint.\n\nThe algorithmâ€™s learning is:\n\n1. Instance-based learning: Here we do not learn weights from training data to predict output (as in model-based algorithms) but use entire training instances to predict output for unseen data.\n\n2. Lazy Learning: Model is not learned using training data prior and the learning process is postponed to a time when prediction is requested on the new instance.\n\n3. Non -Parametric: In KNN, there is no predefined form of the mapping function.\n\n\n</p>\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nImporting the required libraries\n</p>\n","metadata":{}},{"cell_type":"code","source":"# Data manipulation imports\nimport numpy as np\nimport pandas as pd\n\n# Visualization imports\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n%matplotlib inline\n\n# Modeling imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.47948Z","iopub.execute_input":"2022-12-10T14:10:33.479912Z","iopub.status.idle":"2022-12-10T14:10:33.502572Z","shell.execute_reply.started":"2022-12-10T14:10:33.479845Z","shell.execute_reply":"2022-12-10T14:10:33.501018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nImporting the data file (in csv format) into the noteboobk\n</p>\n","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/classified-data/Classified_Data.csv\", index_col=0) \n#Data avaliable from my collection at :https://www.kaggle.com/datasets/tusharaggarwal27/classified-data","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.504891Z","iopub.execute_input":"2022-12-10T14:10:33.505359Z","iopub.status.idle":"2022-12-10T14:10:33.532145Z","shell.execute_reply.started":"2022-12-10T14:10:33.505319Z","shell.execute_reply":"2022-12-10T14:10:33.530784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(11)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.533655Z","iopub.execute_input":"2022-12-10T14:10:33.534058Z","iopub.status.idle":"2022-12-10T14:10:33.555322Z","shell.execute_reply.started":"2022-12-10T14:10:33.534021Z","shell.execute_reply":"2022-12-10T14:10:33.554357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:skyblue;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\n Standardizing the Variables because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nTransforming with StandardScaler\n</p>","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.557567Z","iopub.execute_input":"2022-12-10T14:10:33.558258Z","iopub.status.idle":"2022-12-10T14:10:33.565026Z","shell.execute_reply.started":"2022-12-10T14:10:33.558221Z","shell.execute_reply":"2022-12-10T14:10:33.563377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(data.drop('TARGET CLASS', axis=1)) #Computes the mean and std to be used for scaling ","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.56695Z","iopub.execute_input":"2022-12-10T14:10:33.567318Z","iopub.status.idle":"2022-12-10T14:10:33.582673Z","shell.execute_reply.started":"2022-12-10T14:10:33.567286Z","shell.execute_reply":"2022-12-10T14:10:33.581352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nSetting scaled_features\n</p>","metadata":{}},{"cell_type":"code","source":"scaled_features = scaler.transform(data.drop('TARGET CLASS', axis=1)) #perform Standardization by centering and scaling","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.584625Z","iopub.execute_input":"2022-12-10T14:10:33.585147Z","iopub.status.idle":"2022-12-10T14:10:33.597496Z","shell.execute_reply.started":"2022-12-10T14:10:33.585101Z","shell.execute_reply":"2022-12-10T14:10:33.595811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_features #cheking","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.599449Z","iopub.execute_input":"2022-12-10T14:10:33.6Z","iopub.status.idle":"2022-12-10T14:10:33.61304Z","shell.execute_reply.started":"2022-12-10T14:10:33.599951Z","shell.execute_reply":"2022-12-10T14:10:33.611614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(scaled_features, columns=data.columns[:-1])\ndf","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.614289Z","iopub.execute_input":"2022-12-10T14:10:33.614867Z","iopub.status.idle":"2022-12-10T14:10:33.642282Z","shell.execute_reply.started":"2022-12-10T14:10:33.614796Z","shell.execute_reply":"2022-12-10T14:10:33.641025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nUsing Train Test Split\n</p>","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(scaled_features, data['TARGET CLASS'], test_size=0.33, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.64704Z","iopub.execute_input":"2022-12-10T14:10:33.647404Z","iopub.status.idle":"2022-12-10T14:10:33.656531Z","shell.execute_reply.started":"2022-12-10T14:10:33.647373Z","shell.execute_reply":"2022-12-10T14:10:33.655185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nUsing KNN\n\nRemember that we are trying to come up with a model to predict whether someone will be in the TARGET CLASS or not. We'll start with k=1.\n\n</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nBuilding the model and fitting on traing sets\n</p>","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1) # n_neighbors as 1","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.65851Z","iopub.execute_input":"2022-12-10T14:10:33.659033Z","iopub.status.idle":"2022-12-10T14:10:33.668406Z","shell.execute_reply.started":"2022-12-10T14:10:33.658986Z","shell.execute_reply":"2022-12-10T14:10:33.66736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn.fit(X_train, y_train) # fitting the data","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.669545Z","iopub.execute_input":"2022-12-10T14:10:33.669966Z","iopub.status.idle":"2022-12-10T14:10:33.686139Z","shell.execute_reply.started":"2022-12-10T14:10:33.66993Z","shell.execute_reply":"2022-12-10T14:10:33.684445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPredicting the model on test sets \n</p>","metadata":{}},{"cell_type":"code","source":"y_pred= knn.predict(X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.689761Z","iopub.execute_input":"2022-12-10T14:10:33.690283Z","iopub.status.idle":"2022-12-10T14:10:33.721304Z","shell.execute_reply.started":"2022-12-10T14:10:33.690242Z","shell.execute_reply":"2022-12-10T14:10:33.719934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPredictions and Evaluations and Let's evaluate our KNN Model\n\n\n</p>","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.723095Z","iopub.execute_input":"2022-12-10T14:10:33.72349Z","iopub.status.idle":"2022-12-10T14:10:33.731665Z","shell.execute_reply.started":"2022-12-10T14:10:33.723459Z","shell.execute_reply":"2022-12-10T14:10:33.730028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.733331Z","iopub.execute_input":"2022-12-10T14:10:33.733785Z","iopub.status.idle":"2022-12-10T14:10:33.749507Z","shell.execute_reply.started":"2022-12-10T14:10:33.73374Z","shell.execute_reply":"2022-12-10T14:10:33.74789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nChoosing a k Value; \nNow Let's go ahead and use the elbow method to pick a good K Value:\n</p>","metadata":{}},{"cell_type":"code","source":"error_rate=[]\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    y_pred= knn.predict(X_test)\n    error_rate.append(np.mean(y_pred != y_test))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:33.751156Z","iopub.execute_input":"2022-12-10T14:10:33.751639Z","iopub.status.idle":"2022-12-10T14:10:34.416374Z","shell.execute_reply.started":"2022-12-10T14:10:33.751594Z","shell.execute_reply":"2022-12-10T14:10:34.415323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_rate","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:34.418048Z","iopub.execute_input":"2022-12-10T14:10:34.41837Z","iopub.status.idle":"2022-12-10T14:10:34.425762Z","shell.execute_reply.started":"2022-12-10T14:10:34.418341Z","shell.execute_reply":"2022-12-10T14:10:34.424579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPlotting 'Error Rate vs. K Value'\n</p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:34.42699Z","iopub.execute_input":"2022-12-10T14:10:34.427297Z","iopub.status.idle":"2022-12-10T14:10:34.664769Z","shell.execute_reply.started":"2022-12-10T14:10:34.427267Z","shell.execute_reply":"2022-12-10T14:10:34.663663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:#e71837;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nHere we can see that that after around K>20 the error rate just tends to hover around 0.4 Let's retrain the model with that and check the classification report!\n</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nFIRST A QUICK COMPARISON TO OUR ORIGINAL k=1\n</p>","metadata":{}},{"cell_type":"code","source":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,y_pred))\nprint('\\n')\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:34.667842Z","iopub.execute_input":"2022-12-10T14:10:34.668225Z","iopub.status.idle":"2022-12-10T14:10:34.702497Z","shell.execute_reply.started":"2022-12-10T14:10:34.668191Z","shell.execute_reply":"2022-12-10T14:10:34.701317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nNow a quick COMPARISON to our new k=20\n</p>","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=20)\n\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\n\nprint('WITH K=20')\nprint('\\n')\nprint(confusion_matrix(y_test,y_pred))\nprint('\\n')\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:34.703984Z","iopub.execute_input":"2022-12-10T14:10:34.704334Z","iopub.status.idle":"2022-12-10T14:10:34.745091Z","shell.execute_reply.started":"2022-12-10T14:10:34.704295Z","shell.execute_reply":"2022-12-10T14:10:34.743813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPlotting Accuracy vs K-value (i.e. no. of neighours)\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\naccuracy=[]\n\nfor i in range(1,40):\n    neigh =KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n    yhat = neigh.predict(X_test)\n    accuracy.append(metrics.accuracy_score(y_test, yhat))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:34.746611Z","iopub.execute_input":"2022-12-10T14:10:34.746976Z","iopub.status.idle":"2022-12-10T14:10:35.416836Z","shell.execute_reply.started":"2022-12-10T14:10:34.746944Z","shell.execute_reply":"2022-12-10T14:10:35.415634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:orange;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nPlotting 'accuracy vs. K Value'\n</p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),accuracy,color = 'blue',linestyle='dashed', \n         marker='o',markerfacecolor='red', markersize=10)\nplt.title('accuracy vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Accuracy')\nprint(\"Maximum accuracy:-\",max(accuracy),\"at K =\",accuracy.index(max(accuracy)))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-10T14:10:35.418474Z","iopub.execute_input":"2022-12-10T14:10:35.418795Z","iopub.status.idle":"2022-12-10T14:10:35.596981Z","shell.execute_reply.started":"2022-12-10T14:10:35.418765Z","shell.execute_reply":"2022-12-10T14:10:35.59546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:#a5d610;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nWe are doing something right here, ðŸ˜€, as when k was one recall for 0 & 1 class was around 0.92 , but now with k=20 it's 0.96, ðŸ˜€!!\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:cursive; font-size:25px; color:'darkcyan';\">I brewed this notebook from scratch, If this notebook helped, please consider upvoting and cite me if sharing on other platforms.</p>\n\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;font-size:23px;border-radius:20px\">\n    <a href=\"https://www.linkedin.com/in/tusharaggarwalinseec/\" target=\"_blank\">Lets connect on LinkedIn!</a>\n    \n   </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;border-radius:20px\">\n<a href=\"https://github.com/tushar2704\" target=\"_blank\">Follow me on Github too!</a> </p>\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:23px;border-radius:20px\">\n    <a href=\"https://medium.com/@tushar_aggarwal\" target=\"_blank\">Also checkout my Medium posts!</a>\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}